from bs4 import BeautifulSoup
from collections import OrderedDict
import logging
import sys
import re
import time

try:
    assert int(sys.argv[4]) == 1
except:
    pass
else:
    from transformers import pipeline

import os


NLP_MODEL = os.getenv("NLP_MODEL")
# NLP_MODEL = "distilbert/distilbert-base-cased-distilled-squad"
# NLP_MODEL = "bert-large-uncased-whole-word-masking-finetuned-squad"

logger = logging.getLogger(__name__)


def get_html_elements(html_content, tag_name, class_name):
    elements = None
    try:
        soup = BeautifulSoup(html_content, 'html.parser')
        elements = soup.find_all(tag_name, class_=class_name)
    except Exception as e:
        logger.error(f"Error while parsing the html content: {e}")
    return elements


def get_location(university_home_page):
    soup = BeautifulSoup(university_home_page, 'html.parser')
    address_element = soup.find('address', class_='profile__address--compact')

    address = address_element.get_text(separator='|').split('|')
    try:
        address_line = address[0]
    except:
        address_line = 'N/A'

    try:
        city = address[1]
    except:
        city = 'N/A'

    zipcode = 'N/A'
    try:
        state = address[2]
    except:
        try:
            city, state_zip = address[1].split(',')
            state, zipcode = state_zip.split()
        except:
            state = 'N/A'

    try:
        zipcode = address[3]
    except:
        pass

    return {
        'address': address_line,
        'city': city,
        'state': state,
        'zip': zipcode
    }

def get_innermost_nested_element(parent, nested_tag):
    nested_elements = parent.find_all(nested_tag)
    return (nested_elements[-1].text).rstrip('%')

def get_html_element_by_id(html_content, tag_name, id_name):
    soup = BeautifulSoup(html_content, 'html.parser')
    element = soup.find(tag_name, id=id_name)
    return element

def get_next_page(unordered_list, list_element):
    list_elements = unordered_list.find_all(list_element)
    list_element_anchor_tag = list_elements[-1].find('a')
    if not list_element_anchor_tag:
        return None
    next_page = list_element_anchor_tag['href'].lstrip('#')
    return next_page

def get_next_page_number_from_html_content(html_content):
    unordered_list = get_html_element_by_id(html_content, 'ul', 'alt-style-pagination')
    next_page = get_next_page(unordered_list, 'li')
    # next_page = page-2
    try:
        assert next_page
        next_page_number = int(next_page.split('-')[-1])
    except:
        return None
    return next_page_number

def get_count_of_pages_in_html_content(html_content):
    try:
        ul = get_html_elements(html_content, 'ul', 'MuiPagination-ul nss-nhb8h9')
        assert ul and isinstance(ul, list) and len(ul) == 1
        ul = ul[0]
        page_number = ul.find_all('li')[-2].find('a').text
        page_number = int(page_number)
    except:
        return None
    return page_number

def get_university_list(html_content):
    tag_name = 'a'
    class_name = 'MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover search-result__link nss-6ozsqs'
    elements = get_html_elements(html_content, tag_name, class_name=class_name)
    return elements

def get_about_us_paragraph(html_content):
    class_name = 'details'
    tag_name = 'div'
    elements = get_html_elements(html_content, tag_name, class_name)

    paragraph = ''
    for element in elements:
        paragraph += f"\n{element.text}"

    return paragraph

def get_answer(question, paragraph):
    # print(question)
    # if question in [
    #     'How many active companies have alumni launched?',
    #     'How many jobs were created by alumni?',
    #     "How much annual revenue is generated by alumni's companies?",
    #     "What scientific breakthrough did research from the institution contribute to related to the expanding universe?"
    # ]:
    #     return 'N/A'
    try:
        import sys
        assert int(sys.argv[4]) == 1
        assert paragraph and isinstance(paragraph, str) and len(paragraph) > 0
    except:
        return 'N/A'

    qa_pipeline = pipeline(
        "question-answering",
        model=NLP_MODEL
    )
    return qa_pipeline(
        question=question,
        context=paragraph
    ).get('answer', None)


def get_answer_in_list(question, paragraph):
    try:
        import sys
        assert int(sys.argv[4]) == 1
    except:
        return ['N/A']

    try:
        answers = get_answer(question, paragraph)
        assert answers
        answers = [answers]
    except:
        answers = []

    return answers


def page_not_found(html_content):
    tag_name = 'span'
    class_name = 'no-results__title'

    elements = get_html_elements(html_content, tag_name, class_name)
    return bool(elements)
